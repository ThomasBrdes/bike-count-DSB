{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa46e181",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b319720",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To get some insights\n",
    "# https://github.com/ceptln/paris-bike-traffic-prediction/tree/main\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from submissions.external_data.estimator import _encode_dates, _merge_external_data\n",
    "import utils.get_data as get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e4db5-6407-438a-b58c-59067dcdc2c9",
   "metadata": {},
   "source": [
    "### Function submission kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e0b08f4-fdc6-45d6-b968-07921e101ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_kaggle(model, X_final_test):\n",
    "    y_pred = model.predict(X_final_test)\n",
    "    print(y_pred)\n",
    "    results = pd.DataFrame(\n",
    "        dict(\n",
    "            Id=X_final_test.index,\n",
    "            log_bike_count=y_pred,\n",
    "        )\n",
    "    )\n",
    "    results.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba175e3",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47b8f384-d4b5-42ee-b2dd-c7e13e88ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_external_data(X):\n",
    "    \n",
    "    X = X.copy()\n",
    "    \n",
    "    # merge original data + external data\n",
    "    merged_X_train_external_DATA = get_data._merge_external_data_weather(X)\n",
    "    \n",
    "    # merge original data + external data + holidays\n",
    "    merged_X_train_external_HOLIDAYS = get_data._merge_holidays_week_end(merged_X_train_external_DATA)\n",
    "    \n",
    "    # merge original data + external data + holidays + data COVID\n",
    "    merged_X_train_external_HOLIDAYS_COVID = get_data._merge_Curfews_lockdowns_COVID(merged_X_train_external_HOLIDAYS)\n",
    "    merged_X_train_external_HOLIDAYS_COVID = get_data._merge_indicators_COVID(merged_X_train_external_HOLIDAYS_COVID)\n",
    "    \n",
    "    # merge original data + external data + holidays + data COVID + data accidents\n",
    "    merged_X_train_external_HOLIDAYS_COVID_ACCIDENTS = get_data._merge_road_accidents(merged_X_train_external_HOLIDAYS_COVID)\n",
    "    merged_X_train_external_HOLIDAYS_COVID_ACCIDENTS \n",
    "    return merged_X_train_external_HOLIDAYS_COVID_ACCIDENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50fd8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "X_train, y_train = get_data.get_train_data()\n",
    "X_test, y_test = get_data.get_test_data()\n",
    "X_final_test = get_data.get_final_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95a61e5b-411e-4eb5-9870-a734d4088940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>ff</th>\n",
       "      <th>...</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_lockdown</th>\n",
       "      <th>is_curfew</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>Max_Grav_accidents</th>\n",
       "      <th>Count_accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>293</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>293</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100036719-104036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville NO-SE</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>293</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100036719-103036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville SE-NO</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>293</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100063175-353277233</td>\n",
       "      <td>20 Avenue de Clichy NO-SE</td>\n",
       "      <td>100063175</td>\n",
       "      <td>20 Avenue de Clichy</td>\n",
       "      <td>2020-09-01 01:00:00</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Y2H20073268</td>\n",
       "      <td>48.885290</td>\n",
       "      <td>2.326660</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>293</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             counter_id                       counter_name    site_id  \\\n",
       "0   100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "30  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "31  100036719-104036719  18 quai de l'Hôtel de Ville NO-SE  100036719   \n",
       "32  100036719-103036719  18 quai de l'Hôtel de Ville SE-NO  100036719   \n",
       "33  100063175-353277233          20 Avenue de Clichy NO-SE  100063175   \n",
       "\n",
       "                        site_name                date  \\\n",
       "0   152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "30  152 boulevard du Montparnasse 2020-09-01 01:00:00   \n",
       "31    18 quai de l'Hôtel de Ville 2020-09-01 01:00:00   \n",
       "32    18 quai de l'Hôtel de Ville 2020-09-01 01:00:00   \n",
       "33            20 Avenue de Clichy 2020-09-01 01:00:00   \n",
       "\n",
       "   counter_installation_date counter_technical_id   latitude  longitude   ff  \\\n",
       "0                 2018-12-07          Y2H19070373  48.840801   2.333233  1.6   \n",
       "30                2018-12-07          Y2H19070373  48.840801   2.333233  1.6   \n",
       "31                2017-07-12          Y2H19027732  48.853720   2.357020  1.6   \n",
       "32                2017-07-12          Y2H19027732  48.853720   2.357020  1.6   \n",
       "33                2020-07-22          Y2H20073268  48.885290   2.326660  1.6   \n",
       "\n",
       "    ...  is_holiday  is_weekend  is_lockdown  is_curfew  hosp  rea  incid_rea  \\\n",
       "0   ...       False           0        False      False   293   42        3.0   \n",
       "30  ...       False           0        False      False   293   42        3.0   \n",
       "31  ...       False           0        False      False   293   42        3.0   \n",
       "32  ...       False           0        False      False   293   42        3.0   \n",
       "33  ...       False           0        False      False   293   42        3.0   \n",
       "\n",
       "     rad  Max_Grav_accidents  Count_accidents  \n",
       "0   6641                 0.0              0.0  \n",
       "30  6641                 0.0              0.0  \n",
       "31  6641                 0.0              0.0  \n",
       "32  6641                 0.0              0.0  \n",
       "33  6641                 0.0              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_plus = add_external_data(X_train)\n",
    "X_train_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "12de1990-5753-4250-8714-771742a3d921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>ff</th>\n",
       "      <th>...</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_lockdown</th>\n",
       "      <th>is_curfew</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>Max_Grav_accidents</th>\n",
       "      <th>Count_accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-08-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>284</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-08-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>284</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100036719-104036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville NO-SE</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-08-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>284</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100036719-103036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville SE-NO</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-08-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>284</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>100063175-353277233</td>\n",
       "      <td>20 Avenue de Clichy NO-SE</td>\n",
       "      <td>100063175</td>\n",
       "      <td>20 Avenue de Clichy</td>\n",
       "      <td>2021-08-10 01:00:00</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>Y2H20073268</td>\n",
       "      <td>48.885290</td>\n",
       "      <td>2.326660</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>284</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             counter_id                       counter_name    site_id  \\\n",
       "0   100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "31  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "32  100036719-104036719  18 quai de l'Hôtel de Ville NO-SE  100036719   \n",
       "33  100036719-103036719  18 quai de l'Hôtel de Ville SE-NO  100036719   \n",
       "34  100063175-353277233          20 Avenue de Clichy NO-SE  100063175   \n",
       "\n",
       "                        site_name                date  \\\n",
       "0   152 boulevard du Montparnasse 2021-08-10 01:00:00   \n",
       "31  152 boulevard du Montparnasse 2021-08-10 01:00:00   \n",
       "32    18 quai de l'Hôtel de Ville 2021-08-10 01:00:00   \n",
       "33    18 quai de l'Hôtel de Ville 2021-08-10 01:00:00   \n",
       "34            20 Avenue de Clichy 2021-08-10 01:00:00   \n",
       "\n",
       "   counter_installation_date counter_technical_id   latitude  longitude   ff  \\\n",
       "0                 2018-12-07          Y2H19070373  48.840801   2.333233  1.9   \n",
       "31                2018-12-07          Y2H19070373  48.840801   2.333233  1.9   \n",
       "32                2017-07-12          Y2H19027732  48.853720   2.357020  1.9   \n",
       "33                2017-07-12          Y2H19027732  48.853720   2.357020  1.9   \n",
       "34                2020-07-22          Y2H20073268  48.885290   2.326660  1.9   \n",
       "\n",
       "    ...  is_holiday  is_weekend  is_lockdown  is_curfew  hosp  rea  incid_rea  \\\n",
       "0   ...       False           0        False      False   284   84        6.0   \n",
       "31  ...       False           0        False      False   284   84        6.0   \n",
       "32  ...       False           0        False      False   284   84        6.0   \n",
       "33  ...       False           0        False      False   284   84        6.0   \n",
       "34  ...       False           0        False      False   284   84        6.0   \n",
       "\n",
       "      rad  Max_Grav_accidents  Count_accidents  \n",
       "0   21167                 0.0              0.0  \n",
       "31  21167                 0.0              0.0  \n",
       "32  21167                 0.0              0.0  \n",
       "33  21167                 0.0              0.0  \n",
       "34  21167                 0.0              0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_plus = add_external_data(X_test)\n",
    "X_test_plus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a58b9be-ea52-4498-82eb-402560a7ecdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counter_id</th>\n",
       "      <th>counter_name</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>counter_installation_date</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>counter_technical_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_lockdown</th>\n",
       "      <th>is_curfew</th>\n",
       "      <th>hosp</th>\n",
       "      <th>rea</th>\n",
       "      <th>incid_rea</th>\n",
       "      <th>rad</th>\n",
       "      <th>Max_Grav_accidents</th>\n",
       "      <th>Count_accidents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100049407-353255860</td>\n",
       "      <td>152 boulevard du Montparnasse E-O</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>365</td>\n",
       "      <td>126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100049407-353255859</td>\n",
       "      <td>152 boulevard du Montparnasse O-E</td>\n",
       "      <td>100049407</td>\n",
       "      <td>152 boulevard du Montparnasse</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>48.840801,2.333233</td>\n",
       "      <td>Y2H19070373</td>\n",
       "      <td>48.840801</td>\n",
       "      <td>2.333233</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>365</td>\n",
       "      <td>126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100036719-104036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville NO-SE</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>48.85372,2.35702</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>365</td>\n",
       "      <td>126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100036719-103036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville SE-NO</td>\n",
       "      <td>100036719</td>\n",
       "      <td>18 quai de l'Hôtel de Ville</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>48.85372,2.35702</td>\n",
       "      <td>Y2H19027732</td>\n",
       "      <td>48.853720</td>\n",
       "      <td>2.357020</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>365</td>\n",
       "      <td>126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100063175-353277233</td>\n",
       "      <td>20 Avenue de Clichy NO-SE</td>\n",
       "      <td>100063175</td>\n",
       "      <td>20 Avenue de Clichy</td>\n",
       "      <td>2021-09-10 01:00:00</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>48.88529,2.32666</td>\n",
       "      <td>Y2H20073268</td>\n",
       "      <td>48.885290</td>\n",
       "      <td>2.326660</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>365</td>\n",
       "      <td>126</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             counter_id                       counter_name    site_id  \\\n",
       "0   100049407-353255860  152 boulevard du Montparnasse E-O  100049407   \n",
       "43  100049407-353255859  152 boulevard du Montparnasse O-E  100049407   \n",
       "31  100036719-104036719  18 quai de l'Hôtel de Ville NO-SE  100036719   \n",
       "32  100036719-103036719  18 quai de l'Hôtel de Ville SE-NO  100036719   \n",
       "33  100063175-353277233          20 Avenue de Clichy NO-SE  100063175   \n",
       "\n",
       "                        site_name                date  \\\n",
       "0   152 boulevard du Montparnasse 2021-09-10 01:00:00   \n",
       "43  152 boulevard du Montparnasse 2021-09-10 01:00:00   \n",
       "31    18 quai de l'Hôtel de Ville 2021-09-10 01:00:00   \n",
       "32    18 quai de l'Hôtel de Ville 2021-09-10 01:00:00   \n",
       "33            20 Avenue de Clichy 2021-09-10 01:00:00   \n",
       "\n",
       "   counter_installation_date         coordinates counter_technical_id  \\\n",
       "0                 2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "43                2018-12-07  48.840801,2.333233          Y2H19070373   \n",
       "31                2017-07-12    48.85372,2.35702          Y2H19027732   \n",
       "32                2017-07-12    48.85372,2.35702          Y2H19027732   \n",
       "33                2020-07-22    48.88529,2.32666          Y2H20073268   \n",
       "\n",
       "     latitude  longitude  ...  is_holiday  is_weekend  is_lockdown  is_curfew  \\\n",
       "0   48.840801   2.333233  ...       False           0        False      False   \n",
       "43  48.840801   2.333233  ...       False           0        False      False   \n",
       "31  48.853720   2.357020  ...       False           0        False      False   \n",
       "32  48.853720   2.357020  ...       False           0        False      False   \n",
       "33  48.885290   2.326660  ...       False           0        False      False   \n",
       "\n",
       "    hosp  rea  incid_rea    rad  Max_Grav_accidents  Count_accidents  \n",
       "0    365  126        5.0  21675                 0.0              0.0  \n",
       "43   365  126        5.0  21675                 0.0              0.0  \n",
       "31   365  126        5.0  21675                 0.0              0.0  \n",
       "32   365  126        5.0  21675                 0.0              0.0  \n",
       "33   365  126        5.0  21675                 0.0              0.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test_plus = add_external_data(X_final_test)\n",
    "X_final_test_plus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce50f3",
   "metadata": {},
   "source": [
    "##  Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "758a0e19-e3fa-480a-bb87-747d33ce4512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_dates(X):\n",
    "    \n",
    "    '''\n",
    "    Splits the 'date' columns of the input DataFrame into several columns (year, month, day, weekday, hour)\n",
    "    \n",
    "    Parameters:\n",
    "        X (pd.DataFrame): the dataframe to modify\n",
    "    \n",
    "    Returns:\n",
    "        X (pd.DataFrame): the modified dataframe\n",
    "    '''\n",
    "    \n",
    "    # Duplicate X to work on it\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Create new columns with date parts from X.date\n",
    "    X.loc[:, \"year\"] = X[\"date\"].dt.year\n",
    "    X.loc[:, \"month\"] = X[\"date\"].dt.month\n",
    "    X.loc[:, \"day\"] = X[\"date\"].dt.day\n",
    "    X.loc[:, \"weekday\"] = X[\"date\"].dt.weekday\n",
    "    X.loc[:, \"hour\"] = X[\"date\"].dt.hour\n",
    "\n",
    "    # Adding cosinus and sinus features from date variables to enhance the date periodicity\n",
    "    # X['cos_hour'] = np.cos(X['hour']*(2.*np.pi/24))\n",
    "    # X['sin_hour'] = np.sin(X['hour']*(2.*np.pi/24))\n",
    "    # X['cos_day'] = np.cos(X['day']*(2.*np.pi/30))\n",
    "    # X['sin_day'] = np.sin(X['day']*(2.*np.pi/30))\n",
    "    # X['cos_month'] = np.cos(X['month']*(2.*np.pi/12))\n",
    "    # X['sin_month'] = np.sin(X['month']*(2.*np.pi/12))\n",
    "    # X['cos_weekday'] = np.cos(X['weekday']*(2.*np.pi/7))\n",
    "    # X['sin_weekday'] = np.sin(X['weekday']*(2.*np.pi/7))\n",
    "    \n",
    "    # Clean the new dataframe and return it\n",
    "    X.drop(columns=[\"date\"], inplace=True)\n",
    "    #X.drop(columns=[\"year\", 'month', 'day', 'weekday', 'hour'], inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f3256",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d1acda-3e7e-4112-89df-4b66b0c1042f",
   "metadata": {},
   "source": [
    "## Training without pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8dfe8ea3-9a9c-4d33-bb3f-b24192b9d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RMSE_local(model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    # Fit the pipeline on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on training and test data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE for training and test data\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "    print(f\"Train set RMSE: {rmse_train:.2f}\")\n",
    "    print(f\"Test set RMSE: {rmse_test:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd46e64-3e0d-4e86-a0e6-8009638ba541",
   "metadata": {},
   "source": [
    "### Select features for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1eea8137-4c10-4cb0-98cf-5dd5274aa6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_features = ['date', \"counter_name\", \"site_id\"]\n",
    "\n",
    "not_fixed_features = [\"counter_id\", \"counter_technical_id\", \"counter_installation_date\",\n",
    "                      'site_name'\n",
    "                       'counter_installation_date', \n",
    "                      'counter_technical_id', \n",
    "                      'latitude',\n",
    "                       'longitude', \n",
    "                      'ff', # the wind speed\n",
    "                      'u', # the humidity\n",
    "                      'ssfrai', # the fresh snowfall amount\n",
    "                      'n', # the amount of cloud cover\n",
    "                      'vv', # the visibility\n",
    "                      'rr3', # the precipitation amount over 3 hours\n",
    "                      't', # the temperature\n",
    "                      'is_holiday', # is holidays\n",
    "                       'is_weekend', # is week end\n",
    "                      'is_lockdown', # Lockdown for COVID\n",
    "                      'is_curfew', # Curfew for COVID\n",
    "                      'hosp', # Number of patients currently hospitalised for COVID-19\n",
    "                      'rea', # Number of patients currently in intensive care.\n",
    "                      'incid_rea', # Number of new patients admitted to intensive care in the last 24 hours.\n",
    "                       'rad', # Cumulative number of patients hospitalised for COVID-19 who have returned home due to an improvement in their state of health\n",
    "                      'Max_Grav_accidents', # The maximum severity of all cyclists accidents at a given hour\n",
    "                      'Count_accidents' # the number of accidents at a given hour in Paris\n",
    "                     ]\n",
    "\n",
    "\n",
    "chosen_not_fixed_features = ['t', 'u', 'rr3', 'is_holiday', 'is_weekend']\n",
    "\n",
    "chosen_not_fixed_features = [ 'latitude',\n",
    "                              'longitude',\n",
    "                              'ff', # the wind speed\n",
    "                              'u', # the humidity\n",
    "                              'ssfrai', # the fresh snowfall amount\n",
    "                              'n', # the amount of cloud cover\n",
    "                              'vv', # the visibility\n",
    "                              'rr3', # the precipitation amount over 3 hours\n",
    "                              't', # the temperature\n",
    "                              'is_holiday', # is holidays\n",
    "                               'is_weekend', # is week end\n",
    "                              'is_lockdown', # Lockdown for COVID\n",
    "                              'is_curfew', # Curfew for COVID\n",
    "                              'hosp', # Number of patients currently hospitalised for COVID-19\n",
    "                              'rea', # Number of patients currently in intensive care.\n",
    "                              'incid_rea', # Number of new patients admitted to intensive care in the last 24 hours.\n",
    "                               'rad', # Cumulative number of patients hospitalised for COVID-19 who have returned home due to an improvement in their state of health\n",
    "                              'Max_Grav_accidents', # The maximum severity of all cyclists accidents at a given hour\n",
    "                              'Count_accidents' # the number of accidents at a given hour in Paris\n",
    "                            ]\n",
    "\n",
    "chosen_fixed_features = [ 'ff', # the wind speed\n",
    "                          'u', # the humidity\n",
    "                          'n', # the amount of cloud cover\n",
    "                          'vv', # the visibility\n",
    "                          'rr3', # the precipitation amount over 3 hours\n",
    "                          't', # the temperature\n",
    "                          'is_holiday', # is holidays\n",
    "                           'is_weekend', # is week end\n",
    "                          'is_lockdown', # Lockdown for COVID\n",
    "                          'is_curfew', # Curfew for COVID\n",
    "                          'hosp', # Number of patients currently hospitalised for COVID-19\n",
    "                          'rea', # Number of patients currently in intensive care.\n",
    "                          'incid_rea', # Number of new patients admitted to intensive care in the last 24 hours.\n",
    "                           'rad', # Cumulative number of patients hospitalised for COVID-19 who have returned home due to an improvement in their state of health\n",
    "                          'Max_Grav_accidents', # The maximum severity of all cyclists accidents at a given hour\n",
    "                          'Count_accidents' # the number of accidents at a given hour in Paris\n",
    "                        ]\n",
    "\n",
    "\n",
    "\n",
    "chosen_variables = fixed_features + chosen_fixed_features\n",
    "\n",
    "X_train_plus_chosen = X_train_plus[chosen_variables]\n",
    "X_test_plus_chosen = X_test_plus[chosen_variables]\n",
    "X_final_test_plus_chosen = X_final_test_plus[chosen_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b4cc7058-a45f-4136-9eb5-f5d645ac2b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying continuous variables (float type or int with wide range)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_plus_chosen_FI = _encode_dates(X_train_plus_chosen)\n",
    "#X_train_plus_chosen_FI = pd.get_dummies(X_train_plus_chosen_FI, columns=['site_name'])\n",
    "X_train_plus_chosen_FI = pd.get_dummies(X_train_plus_chosen_FI, columns=['counter_name'])\n",
    "X_train_plus_chosen_FI = pd.get_dummies(X_train_plus_chosen_FI, columns=['site_id'])\n",
    "continuous_columns  = X_train_plus_chosen_FI.select_dtypes(include=['float64', 'float32', 'int64', 'int32']).columns.tolist()\n",
    "X_train_plus_chosen_FI[continuous_columns] = scaler.fit_transform(X_train_plus_chosen_FI[continuous_columns])\n",
    "\n",
    "X_test_plus_chosen_FI = _encode_dates(X_test_plus_chosen)\n",
    "#X_test_plus_chosen_FI = pd.get_dummies(X_test_plus_chosen_FI, columns=['site_name'])\n",
    "X_test_plus_chosen_FI = pd.get_dummies(X_test_plus_chosen_FI, columns=['counter_name'])\n",
    "X_test_plus_chosen_FI = pd.get_dummies(X_test_plus_chosen_FI, columns=['site_id'])\n",
    "X_test_plus_chosen_FI[continuous_columns] = scaler.fit_transform(X_test_plus_chosen_FI[continuous_columns])\n",
    "\n",
    "X_final_test_plus_chosen_FI = _encode_dates(X_final_test_plus_chosen)\n",
    "#X_final_test_plus_chosen_FI = pd.get_dummies(X_final_test_plus_chosen_FI, columns=['site_name'])\n",
    "X_final_test_plus_chosen_FI = pd.get_dummies(X_final_test_plus_chosen_FI, columns=['counter_name'])\n",
    "X_final_test_plus_chosen_FI = pd.get_dummies(X_final_test_plus_chosen_FI, columns=['site_id'])\n",
    "X_final_test_plus_chosen_FI[continuous_columns] = scaler.fit_transform(X_final_test_plus_chosen_FI[continuous_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "da52225f-8e1b-4f99-8887-889af976d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1823\n",
      "[LightGBM] [Info] Number of data points in the train set: 455163, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 3.048589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1823\n",
      "[LightGBM] [Info] Number of data points in the train set: 455163, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 3.048589\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Train set RMSE: 0.38\n",
      "Test set RMSE: 0.82\n"
     ]
    }
   ],
   "source": [
    "# LGMBRegressor\n",
    "\n",
    "params = {\n",
    "        'colsample_bytree': 0.7, \n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 11,\n",
    "        'min_child_samples': 198,\n",
    "        'min_child_weight': 0.1,\n",
    "        'n_estimators': 2000,\n",
    "        'num_leaves': 99,\n",
    "        'reg_alpha': 1, \n",
    "        'reg_lambda': 0.1,\n",
    "        'subsample': 0.5\n",
    "}\n",
    "\n",
    "Regressor = lgb.LGBMRegressor(**params)\n",
    "\n",
    "#Regressor = xgb.XGBRegressor(objectives = 'reg:squarederror')\n",
    "# Ridge\n",
    "#Regressor = Ridge()\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "# Regressor = xgb.XGBRegressor(objectives = 'reg:squarederror',\n",
    "#  learning_rate= 0.01,\n",
    "#  max_depth = 15,\n",
    "#  n_estimators = 1000,\n",
    "#  max_iter = 20,\n",
    "#  verbose = True,\n",
    "#  early_stopping = True)\n",
    "\n",
    "# Initialize the MLPRegressor\n",
    "# Regressor = MLPRegressor(hidden_layer_sizes=(300,), \n",
    "#                          activation='relu', \n",
    "#                          solver='adam', \n",
    "#                          alpha=0.0001, \n",
    "#                          batch_size='auto', \n",
    "#                          learning_rate='constant', \n",
    "#                          learning_rate_init=0.001, \n",
    "#                          max_iter=400, \n",
    "#                          shuffle=True, \n",
    "#                          random_state=None, \n",
    "#                          tol=0.0001, \n",
    "#                          verbose=True,\n",
    "#                          early_stopping=True\n",
    "#                          )\n",
    "\n",
    "# Train model with selected features\n",
    "Regressor.fit(X_train_plus_chosen_FI, y_train)\n",
    "\n",
    "get_RMSE_local(Regressor, X_train_plus_chosen_FI, y_train, X_test_plus_chosen_FI, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8834ae80-4ec9-4560-8e2b-cb01f338a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Randomized search with cross-validation\u001b[39;00m\n\u001b[0;32m     22\u001b[0m randomized_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(Regressor, param_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mrandomized_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_cv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Best estimator\u001b[39;00m\n\u001b[0;32m     26\u001b[0m best_regressor \u001b[38;5;241m=\u001b[39m randomized_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Splitting for validation\n",
    "X_train_cv, X_val_cv, y_train_cv, y_val_cv = train_test_split(X_train_plus_chosen_FI, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "Regressor = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                             max_iter = 5,\n",
    "                             verbose=True,\n",
    "                             early_stopping=True\n",
    "                            )\n",
    "\n",
    "# Define hyperparameter grid (example)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 700, 900, 1100],\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 6, 9, 12],\n",
    "    'subsample': [0.7, 0.8]\n",
    "}\n",
    "\n",
    "# Randomized search with cross-validation\n",
    "randomized_search = RandomizedSearchCV(Regressor, param_grid, n_iter=50, cv=5, scoring='neg_mean_squared_error', verbose = True, n_jobs=-1)\n",
    "randomized_search.fit(X_train_cv, y_train_cv, eval_set=[(X_val_cv, y_val_cv)], verbose=True)\n",
    "\n",
    "# Best estimator\n",
    "best_regressor = randomized_search.best_estimator_\n",
    "\n",
    "# Evaluate the model using your custom function\n",
    "# Assuming get_RMSE_local_wt_pipe is your evaluation function\n",
    "get_RMSE_local(best_regressor, X_train_plus_chosen_FI, y_train, X_test_plus_chosen_FI, y_test)\n",
    "\n",
    "full_params = best_regressor.get_params()\n",
    "print(\"Full Parameters of the Best Regressor:\", full_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9acf51b2-d4c8-4a64-938b-0164fc02dbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 9,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': 700,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 0.7,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None,\n",
       " 'max_iter': 5,\n",
       " 'verbose': True,\n",
       " 'early_stopping': True}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_regressor.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5c1e0-744d-4854-8b1e-a2a3904357ab",
   "metadata": {},
   "source": [
    "### Final csv file with current model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d3989c-e317-4eeb-aa75-7909b3d359ee",
   "metadata": {},
   "source": [
    "#### Train on whole dataset train and test to get the last month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "40c97184-564e-4920-84a8-d857f4451c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496771\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "      <th>counter_name_152 boulevard du Montparnasse E-O</th>\n",
       "      <th>counter_name_152 boulevard du Montparnasse O-E</th>\n",
       "      <th>counter_name_18 quai de l'Hôtel de Ville NO-SE</th>\n",
       "      <th>counter_name_18 quai de l'Hôtel de Ville SE-NO</th>\n",
       "      <th>counter_name_20 Avenue de Clichy NO-SE</th>\n",
       "      <th>...</th>\n",
       "      <th>site_id_100056332</th>\n",
       "      <th>site_id_100056334</th>\n",
       "      <th>site_id_100056335</th>\n",
       "      <th>site_id_100056336</th>\n",
       "      <th>site_id_100057329</th>\n",
       "      <th>site_id_100057380</th>\n",
       "      <th>site_id_100057445</th>\n",
       "      <th>site_id_100060178</th>\n",
       "      <th>site_id_100063175</th>\n",
       "      <th>site_id_300014702</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400125</th>\n",
       "      <td>-1.364391</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>-1.629701</td>\n",
       "      <td>-1.000283</td>\n",
       "      <td>-1.517593</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408305</th>\n",
       "      <td>-1.364391</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>-1.629701</td>\n",
       "      <td>-1.000283</td>\n",
       "      <td>-1.517593</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87516</th>\n",
       "      <td>-1.364391</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>-1.629701</td>\n",
       "      <td>-1.000283</td>\n",
       "      <td>-1.517593</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98518</th>\n",
       "      <td>-1.364391</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>-1.629701</td>\n",
       "      <td>-1.000283</td>\n",
       "      <td>-1.517593</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875137</th>\n",
       "      <td>-1.364391</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>-1.629701</td>\n",
       "      <td>-1.000283</td>\n",
       "      <td>-1.517593</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792857</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.561991</td>\n",
       "      <td>-0.783237</td>\n",
       "      <td>0.048554</td>\n",
       "      <td>1.661061</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805182</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.561991</td>\n",
       "      <td>-0.783237</td>\n",
       "      <td>0.048554</td>\n",
       "      <td>1.661061</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815218</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.561991</td>\n",
       "      <td>-0.783237</td>\n",
       "      <td>0.048554</td>\n",
       "      <td>1.661061</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125979</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.561991</td>\n",
       "      <td>-0.783237</td>\n",
       "      <td>0.048554</td>\n",
       "      <td>1.661061</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135985</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.561991</td>\n",
       "      <td>-0.783237</td>\n",
       "      <td>0.048554</td>\n",
       "      <td>1.661061</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>496771 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            year     month       day   weekday      hour  \\\n",
       "400125 -1.364391  0.736581 -1.629701 -1.000283 -1.517593   \n",
       "408305 -1.364391  0.736581 -1.629701 -1.000283 -1.517593   \n",
       "87516  -1.364391  0.736581 -1.629701 -1.000283 -1.517593   \n",
       "98518  -1.364391  0.736581 -1.629701 -1.000283 -1.517593   \n",
       "875137 -1.364391  0.736581 -1.629701 -1.000283 -1.517593   \n",
       "...          ...       ...       ...       ...       ...   \n",
       "792857  0.000000  1.561991 -0.783237  0.048554  1.661061   \n",
       "805182  0.000000  1.561991 -0.783237  0.048554  1.661061   \n",
       "815218  0.000000  1.561991 -0.783237  0.048554  1.661061   \n",
       "125979  0.000000  1.561991 -0.783237  0.048554  1.661061   \n",
       "135985  0.000000  1.561991 -0.783237  0.048554  1.661061   \n",
       "\n",
       "        counter_name_152 boulevard du Montparnasse E-O  \\\n",
       "400125                                            True   \n",
       "408305                                           False   \n",
       "87516                                            False   \n",
       "98518                                            False   \n",
       "875137                                           False   \n",
       "...                                                ...   \n",
       "792857                                           False   \n",
       "805182                                           False   \n",
       "815218                                           False   \n",
       "125979                                           False   \n",
       "135985                                           False   \n",
       "\n",
       "        counter_name_152 boulevard du Montparnasse O-E  \\\n",
       "400125                                           False   \n",
       "408305                                            True   \n",
       "87516                                            False   \n",
       "98518                                            False   \n",
       "875137                                           False   \n",
       "...                                                ...   \n",
       "792857                                           False   \n",
       "805182                                           False   \n",
       "815218                                           False   \n",
       "125979                                           False   \n",
       "135985                                           False   \n",
       "\n",
       "        counter_name_18 quai de l'Hôtel de Ville NO-SE  \\\n",
       "400125                                           False   \n",
       "408305                                           False   \n",
       "87516                                             True   \n",
       "98518                                            False   \n",
       "875137                                           False   \n",
       "...                                                ...   \n",
       "792857                                           False   \n",
       "805182                                           False   \n",
       "815218                                           False   \n",
       "125979                                           False   \n",
       "135985                                           False   \n",
       "\n",
       "        counter_name_18 quai de l'Hôtel de Ville SE-NO  \\\n",
       "400125                                           False   \n",
       "408305                                           False   \n",
       "87516                                            False   \n",
       "98518                                             True   \n",
       "875137                                           False   \n",
       "...                                                ...   \n",
       "792857                                           False   \n",
       "805182                                           False   \n",
       "815218                                           False   \n",
       "125979                                           False   \n",
       "135985                                           False   \n",
       "\n",
       "        counter_name_20 Avenue de Clichy NO-SE  ...  site_id_100056332  \\\n",
       "400125                                   False  ...              False   \n",
       "408305                                   False  ...              False   \n",
       "87516                                    False  ...              False   \n",
       "98518                                    False  ...              False   \n",
       "875137                                    True  ...              False   \n",
       "...                                        ...  ...                ...   \n",
       "792857                                   False  ...              False   \n",
       "805182                                   False  ...              False   \n",
       "815218                                   False  ...              False   \n",
       "125979                                   False  ...              False   \n",
       "135985                                   False  ...              False   \n",
       "\n",
       "        site_id_100056334  site_id_100056335  site_id_100056336  \\\n",
       "400125              False              False              False   \n",
       "408305              False              False              False   \n",
       "87516               False              False              False   \n",
       "98518               False              False              False   \n",
       "875137              False              False              False   \n",
       "...                   ...                ...                ...   \n",
       "792857              False              False              False   \n",
       "805182              False              False              False   \n",
       "815218              False              False              False   \n",
       "125979              False              False              False   \n",
       "135985              False              False              False   \n",
       "\n",
       "        site_id_100057329  site_id_100057380  site_id_100057445  \\\n",
       "400125              False              False              False   \n",
       "408305              False              False              False   \n",
       "87516               False              False              False   \n",
       "98518               False              False              False   \n",
       "875137              False              False              False   \n",
       "...                   ...                ...                ...   \n",
       "792857               True              False              False   \n",
       "805182              False               True              False   \n",
       "815218              False               True              False   \n",
       "125979              False              False              False   \n",
       "135985              False              False              False   \n",
       "\n",
       "        site_id_100060178  site_id_100063175  site_id_300014702  \n",
       "400125              False              False              False  \n",
       "408305              False              False              False  \n",
       "87516               False              False              False  \n",
       "98518               False              False              False  \n",
       "875137              False               True              False  \n",
       "...                   ...                ...                ...  \n",
       "792857              False              False              False  \n",
       "805182              False              False              False  \n",
       "815218              False              False              False  \n",
       "125979              False              False              False  \n",
       "135985              False              False              False  \n",
       "\n",
       "[496771 rows x 91 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(np.concatenate([y_train, y_test], axis=0)))\n",
    "#pd.concat([X_train_plus_chosen_FI, X_test_plus_chosen_FI], ignore_index=False)\n",
    "pd.concat([X_train_chosen_FI, X_test_chosen_FI], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "add8445e-7c4a-4a97-b87b-a847a4314991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thomas\\anaconda3\\envs\\bikes-count\\lib\\site-packages\\xgboost\\core.py:160: UserWarning: [18:10:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenated_X_train_test = pd.concat([X_train_plus_chosen_FI, X_test_plus_chosen_FI], ignore_index=False)\n",
    "# concatenated_y_train_test = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "concatenated_X_train_test = pd.concat([X_train_chosen_FI, X_test_chosen_FI], ignore_index=False)\n",
    "concatenated_y_train_test = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "Regressor = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    verbose = True\n",
    ")\n",
    "\n",
    "# LGMBRegressor\n",
    "# params = {\n",
    "#         'colsample_bytree': 0.7, \n",
    "#         'learning_rate': 0.01,\n",
    "#         'max_depth': 11,\n",
    "#         'min_child_samples': 198,\n",
    "#         'min_child_weight': 0.1,\n",
    "#         'n_estimators': 2000,\n",
    "#         'num_leaves': 99,\n",
    "#         'reg_alpha': 1, \n",
    "#         'reg_lambda': 0.1,\n",
    "#         'subsample': 0.5\n",
    "# }\n",
    "\n",
    "# Regressor = lgb.LGBMRegressor(**params)\n",
    "\n",
    "# Ridge\n",
    "#Regressor = Ridge()\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "# Regressor = xgb.XGBRegressor({'objective': 'reg:squarederror',\n",
    "#  'learning_rate': 0.05,\n",
    "#  'max_depth': 12,\n",
    "#  'n_estimators': 700,\n",
    "#  'max_iter': 5,\n",
    "#  'verbose': True,\n",
    "#  'early_stopping': True})\n",
    "\n",
    "# Initialize the MLPRegressor\n",
    "# Regressor = MLPRegressor(hidden_layer_sizes=(100,), \n",
    "#                          activation='relu', \n",
    "#                          solver='adam', \n",
    "#                          alpha=0.0001, \n",
    "#                          batch_size='auto', \n",
    "#                          learning_rate='constant', \n",
    "#                          learning_rate_init=0.001, \n",
    "#                          max_iter=100, \n",
    "#                          shuffle=True, \n",
    "#                          random_state=None, \n",
    "#                          tol=0.0001, \n",
    "#                          verbose=True, \n",
    "#                          warm_start=True\n",
    "#                          )\n",
    "\n",
    "# Train model with selected features\n",
    "Regressor.fit(concatenated_X_train_test, concatenated_y_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec820acb-5084-43e7-9ca5-ec650af1fd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6518004  0.5825644  0.47236848 ... 2.6631536  2.003648   2.0176    ]\n"
     ]
    }
   ],
   "source": [
    "# Get submission kaggle to csv\n",
    "submission_kaggle(Regressor, X_final_test_chosen_FI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf8783-4d94-4e39-9855-ddb92bb52a68",
   "metadata": {},
   "source": [
    "### Feature selections with RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "21c28e9d-20e5-45f9-a805-1b7cefd8156e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the XGBRegressor\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Initialize RFECV\n",
    "selector = RFECV(estimator=xgb_reg, step=1, cv=2)\n",
    "\n",
    "# Fit RFECV\n",
    "selector = selector.fit(X_train_plus_chosen_FI, y_train)\n",
    "\n",
    "# Print the optimal number of features\n",
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c00fad72-978b-4a20-aed6-ab00bfe55c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['latitude', 'longitude', 'ff', 'u', 'n', 'vv', 'rr3', 't', 'is_holiday', 'is_weekend', 'is_lockdown', 'is_curfew', 'hosp', 'rea', 'incid_rea', 'rad', 'Max_Grav_accidents', 'Count_accidents', 'month', 'day', 'weekday', 'hour', 'counter_name_152 boulevard du Montparnasse E-O', 'counter_name_152 boulevard du Montparnasse O-E', \"counter_name_18 quai de l'Hôtel de Ville NO-SE\", 'counter_name_20 Avenue de Clichy NO-SE', 'counter_name_20 Avenue de Clichy SE-NO', 'counter_name_254 rue de Vaugirard NE-SO', 'counter_name_254 rue de Vaugirard SO-NE', 'counter_name_27 quai de la Tournelle NO-SE', 'counter_name_27 quai de la Tournelle SE-NO', 'counter_name_28 boulevard Diderot E-O', 'counter_name_28 boulevard Diderot O-E', 'counter_name_36 quai de Grenelle NE-SO', 'counter_name_36 quai de Grenelle SO-NE', 'counter_name_38 rue Turbigo NE-SO', 'counter_name_38 rue Turbigo SO-NE', 'counter_name_39 quai François Mauriac NO-SE', 'counter_name_39 quai François Mauriac SE-NO', 'counter_name_6 rue Julia Bartet NE-SO', 'counter_name_6 rue Julia Bartet SO-NE', 'counter_name_67 boulevard Voltaire SE-NO', 'counter_name_90 Rue De Sèvres NE-SO', 'counter_name_90 Rue De Sèvres SO-NE', \"counter_name_Face 104 rue d'Aubervilliers N-S\", \"counter_name_Face 104 rue d'Aubervilliers S-N\", \"counter_name_Face au 25 quai de l'Oise NE-SO\", \"counter_name_Face au 25 quai de l'Oise SO-NE\", 'counter_name_Face au 4 avenue de la porte de Bagnolet E-O', 'counter_name_Face au 4 avenue de la porte de Bagnolet O-E', \"counter_name_Face au 40 quai D'Issy NE-SO\", \"counter_name_Face au 40 quai D'Issy SO-NE\", 'counter_name_Face au 48 quai de la marne NE-SO', 'counter_name_Face au 48 quai de la marne SO-NE', 'counter_name_Face au 70 quai de Bercy N-S', 'counter_name_Face au 70 quai de Bercy S-N', 'counter_name_Face au 8 avenue de la porte de Charenton NO-SE', 'counter_name_Face au 8 avenue de la porte de Charenton SE-NO', 'counter_name_Pont Charles De Gaulle NE-SO', 'counter_name_Pont Charles De Gaulle SO-NE', 'counter_name_Pont de Bercy NE-SO', 'counter_name_Pont de Bercy SO-NE', 'counter_name_Pont de la Concorde S-N', 'counter_name_Pont des Invalides N-S', 'counter_name_Pont des Invalides S-N', \"counter_name_Quai d'Orsay E-O\", \"counter_name_Quai d'Orsay O-E\", 'counter_name_Totem 64 Rue de Rivoli E-O', 'counter_name_Totem 64 Rue de Rivoli O-E', 'counter_name_Totem 73 boulevard de Sébastopol N-S', 'counter_name_Totem 73 boulevard de Sébastopol S-N', \"counter_name_Totem 85 quai d'Austerlitz NO-SE\", \"counter_name_Totem 85 quai d'Austerlitz SE-NO\", 'counter_name_Totem Cours la Reine E-O', 'counter_name_Totem Cours la Reine O-E', 'counter_name_Voie Georges Pompidou NE-SO', 'counter_name_Voie Georges Pompidou SO-NE', 'site_id_100036718', 'site_id_100036719', 'site_id_100042374', 'site_id_100047545', 'site_id_100049407', 'site_id_100050876', 'site_id_100056329', 'site_id_100056332', 'site_id_100056335', 'site_id_100056336', 'site_id_100057329', 'site_id_100057380', 'site_id_100057445', 'site_id_100063175', 'site_id_300014702']\n"
     ]
    }
   ],
   "source": [
    "# Print selected features\n",
    "selected_features = [feature for feature, selected in zip(X_train_plus_chosen_FI.columns, selector.support_) if selected]\n",
    "print(\"Selected features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6a115a3-9de1-4f58-b4f6-1fc03559ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set RMSE: 0.41\n",
      "Test set RMSE: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Transform training and testing sets\n",
    "X_train_selected = selector.transform(X_train_plus_chosen_FI)\n",
    "X_test_selected = selector.transform(X_test_plus_chosen_FI)\n",
    "\n",
    "# Train model with selected features\n",
    "xgb_reg.fit(X_train_selected, y_train)\n",
    "\n",
    "get_RMSE_local(xgb_reg, X_train_selected, y_train, X_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba8129-c0a4-4f9f-bbd0-f34ac11032f7",
   "metadata": {},
   "source": [
    "## Train with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1e2f20-470c-4b16-b5f8-fc3fcaef4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X_train):\n",
    "    \n",
    "    date_encoder = FunctionTransformer(_encode_dates)\n",
    "    date_cols = _encode_dates(X_train[[\"date\"]]).columns.tolist()\n",
    "\n",
    "    categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    categorical_cols = [\"counter_name\", \"site_name\"]\n",
    "\n",
    "    numeric_encoder = StandardScaler()\n",
    "    numeric_cols = ['latitude', 'longitude', 't', 'ff', 'u', 'ssfrai', 'n', 'vv', 'rr3', 'hosp', 'rea', 'incid_rea', 'rad', 'Count_accidents']\n",
    "    numeric_cols = ['t', 'ff', 'u', 'ssfrai', 'n', 'vv', 'rr3', 'hosp', 'rea', 'incid_rea', 'rad', 'Count_accidents']\n",
    "    #numeric_cols = ['t', 'ff', 'u', 'ssfrai', 'n', 'vv', 'rr3']\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            (\"date\", OneHotEncoder(handle_unknown=\"ignore\"), date_cols),\n",
    "            (\"cat\", categorical_encoder, categorical_cols),\n",
    "            (\"num\", numeric_encoder, numeric_cols),\n",
    "        ],\n",
    "        remainder=\"passthrough\"  # This will pass through other columns not specified\n",
    "    )\n",
    "    return preprocessor, date_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2a9db-0917-4471-ad31-75605ab97db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RMSE_local_pipe(pipe, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    n_folds = 5\n",
    "\n",
    "    # Perform cross-validation and compute the scores\n",
    "    cv_scores_train = cross_val_score(pipe, X_train, y_train, cv=n_folds, scoring='neg_mean_squared_error')\n",
    "    cv_scores_test = cross_val_score(pipe, X_test, y_test, cv=n_folds, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Convert the scores to root mean squared error\n",
    "    rmse_scores_train = np.sqrt(-cv_scores_train)\n",
    "    rmse_scores_test = np.sqrt(-cv_scores_test)\n",
    "    \n",
    "    print(\n",
    "        f\"Train set, RMSE={np.mean(rmse_scores_train):.2f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Test set, RMSE={np.mean(rmse_scores_test):.2f}\"\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acfb9648-35a4-4017-a69f-3ca795c9e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get preprocessor\n",
    "preprocessor, date_encoder = preprocessing(X_train_plus_FI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "286655a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, RMSE=1.74\n",
      "Test set, RMSE=1.45\n"
     ]
    }
   ],
   "source": [
    "# Ridge pipe\n",
    "regressor = Ridge()\n",
    "\n",
    "pipe_Ridge = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Predict data and get RMSE\n",
    "get_RMSE_local(pipe_Ridge, X_train_plus_FI, y_train, X_test_plus_FI, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "983a8190-acd4-49f3-8b0c-05216cf90058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, RMSE=1.70\n",
      "Test set, RMSE=1.42\n"
     ]
    }
   ],
   "source": [
    "# Lasso pipe\n",
    "regressor = Lasso()\n",
    "\n",
    "pipe_Lasso = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Predict data and get RMSE\n",
    "get_RMSE_local(pipe_Lasso, X_train_plus_FI, y_train, X_test_plus_FI, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f12a421-a3fe-4c11-a050-40a3757d9cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, RMSE=1.70\n",
      "Test set, RMSE=1.42\n"
     ]
    }
   ],
   "source": [
    "# ElasticNet pipe\n",
    "regressor = ElasticNet()\n",
    "\n",
    "pipe_ElasticNet = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Predict data and get RMSE\n",
    "get_RMSE_local(pipe_ElasticNet, X_train_plus_FI, y_train, X_test_plus_FI, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e7375-d02d-427a-9f9e-daa526501d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor pipe\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "pipe_RandomForestRegressor = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Predict data and get RMSE\n",
    "get_RMSE_local(pipe_RandomForestRegressor, X_train_plus_FI, y_train, X_test_plus_FI, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0dc76e50-8a83-428b-aabf-94fdea990180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 827\n",
      "[LightGBM] [Info] Number of data points in the train set: 33286, number of used features: 161\n",
      "[LightGBM] [Info] Start training from score 3.490959\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 839\n",
      "[LightGBM] [Info] Number of data points in the train set: 33286, number of used features: 162\n",
      "[LightGBM] [Info] Start training from score 3.475406\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 828\n",
      "[LightGBM] [Info] Number of data points in the train set: 33286, number of used features: 162\n",
      "[LightGBM] [Info] Start training from score 3.427394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 833\n",
      "[LightGBM] [Info] Number of data points in the train set: 33287, number of used features: 162\n",
      "[LightGBM] [Info] Start training from score 3.375315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 813\n",
      "[LightGBM] [Info] Number of data points in the train set: 33287, number of used features: 161\n",
      "[LightGBM] [Info] Start training from score 3.355753\n",
      "Train set, RMSE=0.69\n",
      "Test set, RMSE=0.55\n"
     ]
    }
   ],
   "source": [
    "# LGMBRegressor pipe\n",
    "regressor = lgb.LGBMRegressor()\n",
    "\n",
    "pipe_LGMBRegressor = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Predict data and get RMSE\n",
    "get_RMSE_local(pipe_LGMBRegressor, X_train_plus_FI, y_train, X_test_plus_FI, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f1a8c36-7da7-491a-ad03-9257875daa80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set, RMSE=0.66\n",
      "Test set, RMSE=0.51\n"
     ]
    }
   ],
   "source": [
    "# XGBRegressor pipe\n",
    "\n",
    "best_params = {'colsample_bytree': 0.6154469128110744,\n",
    "              'gamma': 1,\n",
    "              'learning_rate': 0.09803049874792026,\n",
    "              'max_depth': 9,\n",
    "              'n_estimators': 363,\n",
    "              'subsample': 0.5171942605576092}\n",
    "\n",
    "regressor = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                    n_estimators=best_params['n_estimators'],\n",
    "                    max_depth=best_params['max_depth'],\n",
    "                    learning_rate=best_params['learning_rate'],\n",
    "                    subsample=best_params['subsample'],\n",
    "                    colsample_bytree=best_params['colsample_bytree'],\n",
    "                    gamma=best_params['gamma'],\n",
    "                    seed=42\n",
    "            )\n",
    "\n",
    "pipe_XGBRegressor = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Predict data and get RMSE\n",
    "get_RMSE_local(pipe_XGBRegressor, X_train_plus_FI, y_train, X_test_plus_FI, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040716c0-e508-4992-8879-b55f7d3fdb04",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175bcbc-475a-448d-9638-02a02b6432d8",
   "metadata": {},
   "source": [
    "## LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7529a069-9f82-4463-a5c3-345dc3ee5492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012981 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010027 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.979088\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1943\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.125360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1916\n",
      "[LightGBM] [Info] Number of data points in the train set: 364130, number of used features: 181\n",
      "[LightGBM] [Info] Start training from score 3.108453\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 3.059432\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1941\n",
      "[LightGBM] [Info] Number of data points in the train set: 364131, number of used features: 180\n",
      "[LightGBM] [Info] Start training from score 2.970613\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1989\n",
      "[LightGBM] [Info] Number of data points in the train set: 455163, number of used features: 182\n",
      "[LightGBM] [Info] Start training from score 3.048589\n",
      "Best parameters found for LGBM:  {'lgbmregressor__colsample_bytree': 0.5232252063599989, 'lgbmregressor__learning_rate': 0.1315089703802877, 'lgbmregressor__max_depth': 7, 'lgbmregressor__n_estimators': 428, 'lgbmregressor__num_leaves': 26, 'lgbmregressor__subsample': 0.5066324805799333}\n",
      "Lowest RMSE found for LGBM:  0.6860618160438993\n",
      "Test set RMSE of best LGBM model:  0.49583258653055434\n"
     ]
    }
   ],
   "source": [
    "best_params_LGBM = {'lgbmregressor__colsample_bytree': 0.5232252063599989,\n",
    "                    'lgbmregressor__learning_rate': 0.1315089703802877,\n",
    "                    'lgbmregressor__max_depth': 7,\n",
    "                    'lgbmregressor__n_estimators': 428,\n",
    "                    'lgbmregressor__num_leaves': 26,\n",
    "                    'lgbmregressor__subsample': 0.5066324805799333\n",
    "                   }\n",
    "\n",
    "# Define the hyperparameter space for LGBMRegressor\n",
    "param_dist = {\n",
    "    'lgbmregressor__n_estimators': randint(100, 500),\n",
    "    'lgbmregressor__max_depth': randint(3, 10),\n",
    "    'lgbmregressor__learning_rate': uniform(0.01, 0.2),\n",
    "    'lgbmregressor__subsample': uniform(0.5, 0.5),\n",
    "    'lgbmregressor__colsample_bytree': uniform(0.5, 0.5),\n",
    "    'lgbmregressor__num_leaves': randint(20, 40),\n",
    "}\n",
    "\n",
    "# Get preprocessor\n",
    "preprocessor, date_encoder = preprocessing(X_train_plus_FI)\n",
    "pipe_LGMBRegressor = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Create a RandomizedSearchCV object for LightGBM\n",
    "random_search_lgbm = RandomizedSearchCV(\n",
    "    estimator= pipe_LGMBRegressor,  # Ensure your pipeline ends with a LGBMRegressor\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of parameter settings that are sampled\n",
    "    scoring='neg_root_mean_squared_error',  # Scoring metric to optimize\n",
    "    cv=5,  # Number of folds in cross-validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to the data\n",
    "random_search_lgbm.fit(X_train_plus_FI, y_train)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found for LGBM: \", random_search_lgbm.best_params_)\n",
    "print(\"Lowest RMSE found for LGBM: \", np.abs(random_search_lgbm.best_score_))\n",
    "\n",
    "# To predict and get RMSE on the test set using the best LightGBM model\n",
    "best_model_lgbm = random_search_lgbm.best_estimator_\n",
    "y_pred_lgbm = best_model_lgbm.predict(X_test_plus_FI)\n",
    "rmse_test_lgbm = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "print(\"Test set RMSE of best LGBM model: \", rmse_test_lgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7778a4-2277-4e34-84e9-37eb94503b72",
   "metadata": {},
   "source": [
    "## XGBregressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f0e7e00-ed7c-44ae-af5d-852ef8397ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'xgbregressor__colsample_bytree': 0.6154469128110744, 'xgbregressor__gamma': 1, 'xgbregressor__learning_rate': 0.09803049874792026, 'xgbregressor__max_depth': 9, 'xgbregressor__n_estimators': 363, 'xgbregressor__subsample': 0.5171942605576092}\n",
      "Lowest RMSE found:  0.677347199973148\n",
      "Test set RMSE of best model:  0.4584068511534211\n"
     ]
    }
   ],
   "source": [
    "# Define the hyperparameter space\n",
    "param_dist = {\n",
    "    'xgbregressor__n_estimators': randint(100, 500),\n",
    "    'xgbregressor__max_depth': randint(3, 10),\n",
    "    'xgbregressor__learning_rate': uniform(0.01, 0.2),\n",
    "    'xgbregressor__subsample': uniform(0.5, 0.5),\n",
    "    'xgbregressor__colsample_bytree': uniform(0.5, 0.5),\n",
    "    'xgbregressor__gamma': [0, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Get preprocessor\n",
    "preprocessor, date_encoder = preprocessing(X_train_plus_FI)\n",
    "pipe_XGBregressor = make_pipeline(date_encoder, preprocessor, regressor)\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipe_XGBregressor,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of parameter settings that are sampled\n",
    "    scoring='neg_root_mean_squared_error',  # Scoring metric to optimize\n",
    "    cv=5,  # Number of folds in cross-validation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit to the data\n",
    "random_search.fit(X_train_plus_FI, y_train)\n",
    "\n",
    "# Print the best parameters and lowest RMSE\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Lowest RMSE found: \", np.abs(random_search.best_score_))\n",
    "\n",
    "# To predict and get RMSE on the test set using the best model\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_plus_FI)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test set RMSE of best model: \", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c591331-3880-41b4-acab-c2d1e5723d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
